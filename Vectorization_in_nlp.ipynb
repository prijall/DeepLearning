{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbxNJJmGCs6w6fg7J0XAoA"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### One hot encoding:\n",
        "- It is the method of representing text/tokens into numerical values. for example, text='i love you'. now we spilt the sentence into tokens and each tokens have unique vectors. The onehot encoding for the text can be [[1, 0, 0], [0, 1, 0], [0, 0,1]], where i=[1, 0, 0], love=[0, 1, 0], you=[0, 0, 1]. There are 3 elements in the vector because we have to create the vector size equal to that of size of tokens."
      ],
      "metadata": {
        "id": "i9OQvFf3wHO7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MCPvyeNfrJA-"
      },
      "outputs": [],
      "source": [
        "documents=['Dog bites man.', 'Man bites dog.', 'Dog eats meat.', 'Man eats food']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_doc=[doc.lower().replace('.', '') for doc in documents]\n",
        "processed_doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DSQj8RBrj8q",
        "outputId": "74b6b1e8-9497-45cc-c4d4-5db4e6a7fdb9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dog bites man', 'man bites dog', 'dog eats meat', 'man eats food']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@ Building Vocabulary:\n",
        "vocab={}\n",
        "count=0\n",
        "for doc in processed_doc:\n",
        "  for word in doc.split():\n",
        "    if word not in vocab:\n",
        "      count+=1\n",
        "      vocab[word]=count\n",
        "\n",
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gL-GDzasUE5",
        "outputId": "c18a6046-3749-4aeb-95d7-b376f5e36770"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'dog': 1, 'bites': 2, 'man': 3, 'eats': 4, 'meat': 5, 'food': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@ onehot encoding for any string:\n",
        "def get_onehot_vector(text):\n",
        "  onehot_encoded=[]\n",
        "  for word in text.split():\n",
        "    temp=[0]*len(vocab)\n",
        "    if word in vocab:\n",
        "       temp[vocab[word]-1]=1\n",
        "    onehot_encoded.append(temp)\n",
        "  return onehot_encoded"
      ],
      "metadata": {
        "id": "PAWLYP-7ti57"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_onehot_vector(processed_doc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U63993WwvUsa",
        "outputId": "74c9555d-24ac-4d4b-d511-db0ce30f5829"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### N-gram\n",
        "- It works by breaking text into chunks of n contiguous words (or\n",
        "tokens). This can help us capture some context,. Each chunk is called an n-gram. The corpus vocabulary, V, is then nothing but a\n",
        "collection of all unique n-grams across the text corpus. Then, each document in the\n",
        "corpus is represented by a vector of length |V|. This vector simply contains the fre‐\n",
        "quency counts of n-grams present in the document and zero for the n-grams that are\n",
        "not present."
      ],
      "metadata": {
        "id": "Bnq9K_97Az89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "gGPEWux-71WU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_vect=CountVectorizer(ngram_range=(1,3)) #unigram, bigram, trigram\n",
        "\n",
        "#bagofword:\n",
        "bow=count_vect.fit_transform(processed_doc)\n",
        "\n",
        "#for vocabulary mapping:\n",
        "print('Our Vocabulary:', count_vect.vocabulary_)\n",
        "\n",
        "# bow for first two document:\n",
        "print(\"BOW of ''dog bites man:\", bow[0].toarray())\n",
        "print(\"BoW representation for 'man bites dog: \",bow[1].toarray())\n",
        "\n",
        "#for new text:\n",
        "temp=count_vect.transform(['dog and dog are friends'])\n",
        "\n",
        "print(\"Bow representation for 'dog and dog are friends':\", temp.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2JjCYlQ8AUk",
        "outputId": "4f080180-f1a6-4d93-90b7-333245465371"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our Vocabulary: {'dog': 3, 'bites': 0, 'man': 12, 'dog bites': 4, 'bites man': 2, 'dog bites man': 5, 'man bites': 13, 'bites dog': 1, 'man bites dog': 14, 'eats': 8, 'meat': 17, 'dog eats': 6, 'eats meat': 10, 'dog eats meat': 7, 'food': 11, 'man eats': 15, 'eats food': 9, 'man eats food': 16}\n",
            "BOW of ''dog bites man: [[1 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0]]\n",
            "BoW representation for 'man bites dog:  [[1 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0]]\n",
            "Bow representation for 'dog and dog are friends': [[0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TF-IDF\n",
        "- if a word w appears many times in a docu‐\n",
        "ment di\n",
        " but does not occur much in the rest of the documents dj\n",
        " in the corpus, then\n",
        "the word w must be of great importance to the document di\n",
        ". The importance of w\n",
        "should increase in proportion to its frequency in di\n",
        ", but at the same time, its impor‐\n",
        "tance should decrease in proportion to the word’s frequency in other documents dj\n",
        " in\n",
        "the corpus. Mathematically, this is captured using two quantities: TF and IDF. The\n",
        "two are then combined to arrive at the TF-IDF score."
      ],
      "metadata": {
        "id": "tvw3HBd-BLXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "NjOsjGsn_4W0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf=TfidfVectorizer()\n",
        "bow_tf=tfidf.fit_transform(processed_doc)\n",
        "print(tfidf.idf_)\n",
        "print(tfidf.get_feature_names_out())\n",
        "\n",
        "temp = tfidf.transform([\"dog and man are friends\"])\n",
        "print(\"Tfidf representation for 'dog and man are friends':\\n\", temp.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2qUrGzjAElN",
        "outputId": "06189c28-8ba2-40f4-816b-aed5d524320a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.51082562 1.22314355 1.51082562 1.91629073 1.22314355 1.91629073]\n",
            "['bites' 'dog' 'eats' 'food' 'man' 'meat']\n",
            "Tfidf representation for 'dog and man are friends':\n",
            " [[0.         0.70710678 0.         0.         0.70710678 0.        ]]\n"
          ]
        }
      ]
    }
  ]
}