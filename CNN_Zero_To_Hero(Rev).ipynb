{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4BKOQKCkY3GUGG6Al9p/Y"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "S0Mk-tp_4Qy7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np, pandas as pd, glob,  time\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms, models, datasets\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device='cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "C29DM4yJ462X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GenderAge(Dataset):\n",
        "  def __init__(self, df):\n",
        "    self.df=df\n",
        "    self.normalize=transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "  def __getitem__(self, ix):\n",
        "    f=self.df.iloc[ix].squeeze()\n",
        "    file=f.file\n",
        "    gen=f.gender=='Female'\n",
        "    age=f.age\n",
        "    im=cv2.imread(file)\n",
        "    im=cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
        "    return im, age, gen\n",
        "\n",
        "  def preprocess_image(self, im):\n",
        "    im=cv2.resize(im, (224, 224))\n",
        "    im=torch.tensor(im).permute(2, 0, 1)\n",
        "    im=self.normalize(im/255.)\n",
        "    return im[1]\n",
        "\n",
        "  def collate_fn(self, batch):\n",
        "    'used during data loading'\n",
        "    ims, ages, genders=[], [], []\n",
        "\n",
        "    for im, age, gender in batch:\n",
        "      im=self.preprocess_image(im)\n",
        "      ims.append(im)\n",
        "\n",
        "      ages.append(float(int(age)/80))\n",
        "      genders.append(float(gender))\n",
        "\n",
        "    ages, genders=[torch.tensor(x).to(device).float() for x in [ages, genders]]\n",
        "    ims=torch.cat(ims).to(device)\n",
        "    return ims, ages, genders"
      ],
      "metadata": {
        "id": "xWvjqLN35AW-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}