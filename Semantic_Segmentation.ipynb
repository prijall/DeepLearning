{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO5nWvqRe9q5iuoYvgMW24Y"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@ Downloading necessary data:\n",
        "import os\n",
        "if not os.path.exists('dataset1'):\n",
        "  !wget -q https://www.dropbox.com/s/0pigmmmynbf9xwq/dataset1.zip\n",
        "  !unzip -q dataset1.zip\n",
        "  !rm dataset1.zip\n",
        "  !pip install -q torch_snippets pytorch_model_summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qE9HCC-bxll",
        "outputId": "2dba2e34-ef9e-4c0f-f6a1-1ded9d0012cd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/78.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.7/218.7 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.0/99.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@ Importing necessaries dependencies:\n",
        "import torch\n",
        "from torch_snippets import *\n",
        "from torchvision import transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import nn\n",
        "device ='cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "98j7VB54chxM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@ function for image transformation:\n",
        "tfms=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225]) # accord to imagenet dataset\n",
        "])"
      ],
      "metadata": {
        "id": "4lMQHX20dJ9d"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Architecture for image segmentation"
      ],
      "metadata": {
        "id": "_IsCunlsd3tI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ defining convolution blocks:\n",
        "def conv(in_channels, out_channels):\n",
        "  return nn.Sequential(\n",
        "      nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
        "      nn.BatchNorm2d(out_channels),\n",
        "      nn.ReLU(inplace=True)\n",
        "  )"
      ],
      "metadata": {
        "id": "tF0dt_5id81c"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@ defining Up-Convolution:\n",
        "def up_conv(in_channels, out_channels):\n",
        "  return nn.Sequential(\n",
        "      nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2), # ensure image upscaling\n",
        "      nn.ReLU(inplace=True)\n",
        "  )"
      ],
      "metadata": {
        "id": "9utytDAkfUfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@ Defining Network Class:\n",
        "from torchvision.models import vgg16_bn # for large scale\n",
        "class UNet(nn.Module):\n",
        "  def __init__(self, pretrained=True, out_channels=12):\n",
        "    super().__init__()\n",
        "    self.encoder=vgg16_bn(pretrained=pretrained).features # excluding FC at end\n",
        "\n",
        "    # encoder blocks\n",
        "    self.block1=nn.Sequential(*self.encoder[:6])\n",
        "    self.block2=nn.Sequential(*self.encoder[6:13])\n",
        "    self.block3=nn.Sequential(*self.encoder[13:20])\n",
        "    self.block4=nn.Sequential(*self.encoder[20:27])\n",
        "    self.block5=nn.Sequential(*self.encoder[27:34])\n",
        "    self.bottleneck=nn.Sequential(*self.enocder[34:]) #acts between encoder and decoder"
      ],
      "metadata": {
        "id": "Aafjc45IgLMk"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}