{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMS42cHXOn6YvmDxaG0n5Yj"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ny37g2R1JWq7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What are experts?\n",
        "- Experts are group of neural network also called feed forward layer in dense layer. Instead of using dense layer, we divide neural network in many of small type(same input, hidden and output layers).\n",
        "\n",
        "## What is GeLU?\n",
        "- Stands for Gaussian Error Linear Unit\n",
        "- uses Cumulative Distributive function for small negatives\n",
        "- better then relu as it doesn't neglate negatives"
      ],
      "metadata": {
        "id": "RqcTWILgK0jY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Expert(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "    super().__init__()\n",
        "    self.net=nn.Sequential(\n",
        "        nn.Linear(input_dim, hidden_dim),\n",
        "        nn.GeLU(),\n",
        "        nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    )\n"
      ],
      "metadata": {
        "id": "oJWenpR2Jx8o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}