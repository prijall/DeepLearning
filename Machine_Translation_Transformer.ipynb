{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "MnFZEmaqZvmY"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf### models\n",
        "import numpy as np### math computations\n",
        "import matplotlib.pyplot as plt### plotting bar chart\n",
        "import sklearn### machine learning library\n",
        "import cv2## image processing\n",
        "from sklearn.metrics import confusion_matrix, roc_curve### metrics\n",
        "import seaborn as sns### visualizations\n",
        "import datetime\n",
        "import pathlib\n",
        "import io\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import time\n",
        "from numpy import random\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_probability as tfp\n",
        "from keras.models import Model\n",
        "from keras.layers import Layer\n",
        "from keras.layers import (Dense,Flatten,SimpleRNN,InputLayer,Conv1D,Bidirectional,GRU,LSTM,BatchNormalization,Dropout,Input, Embedding,TextVectorization)\n",
        "from keras.losses import BinaryCrossentropy,CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
        "from keras.metrics import Accuracy,TopKCategoricalAccuracy, CategoricalAccuracy, SparseCategoricalAccuracy\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import MultiHeadAttention, LayerNormalization\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "from tensorboard.plugins import projector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9Bkvwggaepq",
        "outputId": "6b2f44b4-eb51-4891-f152-e024a045c279"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-20 14:00:21--  https://www.manythings.org/anki/fra-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7943074 (7.6M) [application/zip]\n",
            "Saving to: ‘fra-eng.zip’\n",
            "\n",
            "fra-eng.zip         100%[===================>]   7.57M  17.6MB/s    in 0.4s    \n",
            "\n",
            "2025-01-20 14:00:22 (17.6 MB/s) - ‘fra-eng.zip’ saved [7943074/7943074]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#@ Downloading datasets:\n",
        "!wget https://www.manythings.org/anki/fra-eng.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzuI4hW6aq_q",
        "outputId": "a10a97f1-075c-4a90-bfb4-c6546f69017f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/fra-eng.zip\n",
            "  inflating: /content/dataset/_about.txt  \n",
            "  inflating: /content/dataset/fra.txt  \n"
          ]
        }
      ],
      "source": [
        "!unzip '/content/fra-eng.zip' -d '/content/dataset' # -d flag specifies directories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPc5HmT4bR4C"
      },
      "source": [
        "#### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0GEjkt5-bT6B"
      },
      "outputs": [],
      "source": [
        "text_dataset=tf.data.TextLineDataset('/content/dataset/fra.txt') #each line is treated as separate string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y__LTpfEbuhy",
        "outputId": "ec679afd-5ce9-40e6-c523-cd20910ad27e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'Go.\\tVa !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)', shape=(), dtype=string)\n",
            "tf.Tensor(b'Go.\\tMarche.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8090732 (Micsmithel)', shape=(), dtype=string)\n",
            "tf.Tensor(b'Go.\\tEn route !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8267435 (felix63)', shape=(), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "for i in text_dataset.take(3):\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yHGUPjuwb6Gx"
      },
      "outputs": [],
      "source": [
        "#@ Setting up the Parameters:\n",
        "VOCAB_SIZE=20000 #unique tokens from dataset, setting value 20000 for efficiency\n",
        "ENGLISH_SEQUENCE_LENGTH=32 #max length of i/p sequence[in tokens]\n",
        "FRENCH_SEQUENCE_LENGTH=32 #max len of o/p sequence[in tokens]\n",
        "EMBEDDINGS_DIM=512 #size of vectors to represent tokens(as per paper)\n",
        "BATCH_SIZE=128 #for data size processed during training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hAuTBC_EeFMK"
      },
      "outputs": [],
      "source": [
        "#@ for english word:\n",
        "english_vectorize_layer=TextVectorization(\n",
        "                      standardize='lower_and_strip_punctuation',\n",
        "                      max_tokens=VOCAB_SIZE,\n",
        "                      output_mode='int', #mapping wrt to the integer index\n",
        "                      output_sequence_length=ENGLISH_SEQUENCE_LENGTH\n",
        ")\n",
        "\n",
        "#@ for french word:\n",
        "french_vectorize_layer=TextVectorization(\n",
        "                       standardize='lower_and_strip_punctuation',\n",
        "                       max_tokens=VOCAB_SIZE,\n",
        "                       output_mode='int',\n",
        "                       output_sequence_length=FRENCH_SEQUENCE_LENGTH\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nlKHREVNhT2i"
      },
      "outputs": [],
      "source": [
        "def seperator(input_text):\n",
        "  split_text=tf.strings.split(input_text, '\\t')\n",
        "  return {\n",
        "      'input_1':split_text[0:1],\n",
        "      'input_2':'starttoken' + split_text[1:2]\n",
        "      }, split_text[1:2]+' endtoken'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndmYklVTi-IJ",
        "outputId": "5bf8af34-72bd-4c16-d17b-b08934b4dfc4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'hello'], dtype=object)>,\n",
              "  'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttokenprijal'], dtype=object)>},\n",
              " <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'prijal endtoken'], dtype=object)>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "text='hello\\tprijal'\n",
        "seperator(text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ustOzRdroLei"
      },
      "outputs": [],
      "source": [
        "#@ Initializing dataset:\n",
        "init_dataset=text_dataset.map(seperator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukk0KU5TpH3a",
        "outputId": "03d022e4-88ac-4196-da28-9c34816cdc19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttokenVa !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Va ! endtoken'], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttokenMarche.'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Marche. endtoken'], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttokenEn route !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'En route ! endtoken'], dtype=object)>)\n"
          ]
        }
      ],
      "source": [
        "for i in init_dataset.take(3):\n",
        "  print(i)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCOUUsunpsix"
      },
      "source": [
        "### Vocab Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zDyJI27QpvNp"
      },
      "outputs": [],
      "source": [
        "english_training_data=init_dataset.map(lambda x, y:x['input_1'])\n",
        "english_vectorize_layer.adapt(english_training_data)\n",
        "\n",
        "french_training_data=init_dataset.map(lambda x, y:y)\n",
        "french_vectorize_layer.adapt(french_training_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "V5DDzmf8L_fZ"
      },
      "outputs": [],
      "source": [
        "#@ Grouping and  Vectorization for training:\n",
        "def vectorizer(inputs, output):\n",
        "  return {'input_1':english_vectorize_layer(inputs['input_1']),\n",
        "          'input_2':french_vectorize_layer(inputs['input_2'])}, french_vectorize_layer(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDlEbt5XM4r5",
        "outputId": "10270836-23f0-4b58-c08e-3ec211321215"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_MapDataset element_spec=({'input_1': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'input_2': TensorSpec(shape=(None,), dtype=tf.string, name=None)}, TensorSpec(shape=(None,), dtype=tf.string, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "init_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "HW8hWSGHNAbZ"
      },
      "outputs": [],
      "source": [
        "dataset=init_dataset.map(vectorizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5R0qqzbNYFZ",
        "outputId": "f2f61ff3-c26a-4aeb-e43c-bca7d848e3ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttokenVa !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Va ! endtoken'], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttokenMarche.'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Marche. endtoken'], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttokenEn route !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'En route ! endtoken'], dtype=object)>)\n"
          ]
        }
      ],
      "source": [
        "for i in init_dataset.take(3):\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Z-KNkkdXNfBx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d620a8c-e4e5-4610-b3b6-d3713681d050"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'input_1': <tf.Tensor: shape=(1, 32), dtype=int64, numpy=\n",
            "array([[45,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])>, 'input_2': <tf.Tensor: shape=(1, 32), dtype=int64, numpy=\n",
            "array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>}, <tf.Tensor: shape=(1, 32), dtype=int64, numpy=\n",
            "array([[103,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0]])>)\n"
          ]
        }
      ],
      "source": [
        "for i in dataset.take(1):\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "vQeOs1m8Nooa"
      },
      "outputs": [],
      "source": [
        "dataset=dataset.shuffle(2048).unbatch().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "3MPd8xmaN45p"
      },
      "outputs": [],
      "source": [
        "NUM_BATCHES=int(200000/BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "T3LvhBFsOCcy"
      },
      "outputs": [],
      "source": [
        "#@ Training and testing split\n",
        "train_dataset=dataset.take(int(0.9*NUM_BATCHES))\n",
        "val_dataset=dataset.skip(int(0.9*NUM_BATCHES))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXIaPrbnOWh5"
      },
      "source": [
        "### Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "UuLziKTkOZyh"
      },
      "outputs": [],
      "source": [
        "#@ Positional Encoding:\n",
        "def PositionalEncoding(d_model, SEQUENCE_LENGTH):\n",
        "  output=[]\n",
        "  for pos in range(SEQUENCE_LENGTH):\n",
        "    PE=np.zeros(d_model)\n",
        "    for i in range(d_model):\n",
        "      if i % 2 == 0: #even position, sine formula is used\n",
        "        PE[i]=np.sin(pos/(10000**(2*i/d_model)))\n",
        "      else:\n",
        "        PE[i]=np.cos(pos/(10000**(2*i/d_model)))\n",
        "    output.append(tf.expand_dims(PE, axis=0))\n",
        "  out=tf.concat(output, axis=0)\n",
        "  out=tf.expand_dims(out, axis=0)\n",
        "  return tf.cast(out, dtype=tf.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Am40vFY8Q0LS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f29dbcc8-09df-4fd9-931f-db3dcc88312a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[ 0.0000000e+00  1.0000000e+00  0.0000000e+00 ...  1.0000000e+00\n",
            "    0.0000000e+00  1.0000000e+00]\n",
            "  [ 8.4147096e-01  5.6969500e-01  8.0196178e-01 ...  1.0000000e+00\n",
            "    1.0746079e-08  1.0000000e+00]\n",
            "  [ 9.0929741e-01 -3.5089520e-01  9.5814437e-01 ...  1.0000000e+00\n",
            "    2.1492157e-08  1.0000000e+00]\n",
            "  ...\n",
            "  [-6.6363388e-01 -9.5558822e-01  9.6020764e-01 ...  1.0000000e+00\n",
            "    3.1163626e-07  1.0000000e+00]\n",
            "  [-9.8803163e-01 -7.8659910e-01  3.4962672e-01 ...  1.0000000e+00\n",
            "    3.2238236e-07  1.0000000e+00]\n",
            "  [-4.0403765e-01  5.9345119e-02 -5.4249090e-01 ...  1.0000000e+00\n",
            "    3.3312844e-07  1.0000000e+00]]], shape=(1, 32, 512), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "print(PositionalEncoding(512, 32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqa_KTf3T5Is"
      },
      "source": [
        "### Input Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "xflRdAcHT89U"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Layer, Dense\n",
        "class Embeddings(Layer):\n",
        "  def __init__(self, sequence_length, vocab_size, embedding_dim):\n",
        "    super(Embeddings, self).__init__()\n",
        "    self.token_embeddings=Embedding(input_dim=vocab_size, output_dim=embedding_dim)\n",
        "    self.sequence_length=sequence_length\n",
        "    self.vocab_size=vocab_size\n",
        "    self.embedding_dim=embedding_dim\n",
        "\n",
        "  def call(self, inputs):\n",
        "    embedded_tokens=self.token_embeddings(inputs)\n",
        "    embedded_positions=PositionalEncoding(self.embedding_dim, self.sequence_length)\n",
        "    mask=tf.math.not_equal(inputs, 0)\n",
        "    return embedded_tokens + embedded_positions, mask\n",
        "\n",
        "  # def compute_mask(self, inputs, mask=None):\n",
        "  #   return tf.math.not_equal(inputs, 0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noFlpky0YjJX"
      },
      "source": [
        "### Custome Attention Layer\n",
        "\n",
        "- Self attention layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "2DVoYgd-YrMN"
      },
      "outputs": [],
      "source": [
        "class CustomSelfAttention(Layer):\n",
        "  def __init__(self, model_size):\n",
        "    super(CustomSelfAttention, self).__init__()\n",
        "    self.model_size=model_size\n",
        "\n",
        "  def call(self, query, key, value, masking):\n",
        "    score=tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "    score/= tf.math.sqrt(tf.cast(self.model_size, dtype=tf.float32))\n",
        "\n",
        "    masking=tf.cast(masking, dtype=tf.float32)\n",
        "    score -= (1.0-masking)* 1e10\n",
        "\n",
        "    attention_weights=tf.nn.softmax(score, axis=1) * masking\n",
        "\n",
        "    head_output=tf.matmul(attention_weights, value)\n",
        "\n",
        "    return head_output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-headed Attention\n",
        "- Multihead Attention allows model to focus on different part of input sequence simultaneously and combine these prespective into comprehensive representation.\n",
        "\n",
        "- For example: \"Harry saw a man with binoculars'. This sentence can have two meanings, they are either it can be harry saw a man using binoculars or it can be harry saw a man who has binoculars. These both can be correct. So transformer has to understand both these meanings which self-attention fails to recognize that's why multi-head attention is used."
      ],
      "metadata": {
        "id": "f1Vqrwn1Sdsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(Layer):\n",
        "    def __init__(self, n_heads, key_dim):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "\n",
        "        self.n_heads = n_heads\n",
        "        self.dense_q = [Dense(key_dim // n_heads) for _ in range(n_heads)]\n",
        "        self.dense_k = [Dense(key_dim // n_heads) for _ in range(n_heads)]\n",
        "        self.dense_v = [Dense(key_dim // n_heads) for _ in range(n_heads)]\n",
        "        self.dense_o = Dense(key_dim)\n",
        "        self.attention = CustomSelfAttention(key_dim)\n",
        "\n",
        "    def call(self, query, key, value, attention_mask=None):\n",
        "        heads = []\n",
        "\n",
        "        for i in range(self.n_heads):\n",
        "            q = self.dense_q[i](query)\n",
        "            k = self.dense_k[i](key)\n",
        "            v = self.dense_v[i](value)\n",
        "\n",
        "            # Pass mask as None if not provided\n",
        "            head = self.attention(q, k, v, masking=attention_mask if attention_mask is not None else tf.zeros_like(query))\n",
        "            heads.append(head)\n",
        "\n",
        "        # Concatenate all heads and apply output transformation\n",
        "        heads = tf.concat(heads, axis=2)\n",
        "        heads = self.dense_o(heads)\n",
        "        return heads\n",
        "\n"
      ],
      "metadata": {
        "id": "XadG1w2LSioN"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder"
      ],
      "metadata": {
        "id": "PfIpdo0cZhm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Layer, Dense, LayerNormalization\n",
        "import tensorflow as tf\n",
        "\n",
        "class Encoder(Layer):\n",
        "    def __init__(self, embeddings_dim, dense_dim, n_heads):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embeddings_dim = embeddings_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "        # Initialize the multi-head attention layer\n",
        "        self.attention = MultiHeadAttention(n_heads=n_heads, key_dim=embeddings_dim)\n",
        "\n",
        "        # Dense projection layers\n",
        "        self.dense_projection = tf.keras.Sequential([\n",
        "            Dense(self.dense_dim, activation='relu'),\n",
        "            Dense(self.embeddings_dim)\n",
        "        ])\n",
        "\n",
        "        # Layer normalization layers\n",
        "        self.layernorm1 = LayerNormalization()\n",
        "        self.layernorm2 = LayerNormalization()\n",
        "\n",
        "        # Masking support\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        # If mask is provided, handle it; otherwise, skip masking logic\n",
        "        if mask is not None:\n",
        "            mask = tf.cast(mask[:, tf.newaxis, :], dtype='int32')\n",
        "            T = tf.shape(mask)[2]\n",
        "            padding_mask = tf.repeat(mask, T, axis=1)\n",
        "        else:\n",
        "            padding_mask = None\n",
        "\n",
        "        # Apply the multi-head attention layer\n",
        "        attention_output = self.attention(query=inputs, value=inputs, key=inputs, attention_mask=padding_mask)\n",
        "\n",
        "        # Apply residual connection and layer normalization after attention\n",
        "        projection_input = self.layernorm1(inputs + attention_output)\n",
        "\n",
        "        # Dense projection and residual connection\n",
        "        projection_output = self.dense_projection(projection_input)\n",
        "        return self.layernorm2(projection_input + projection_output)\n",
        "\n"
      ],
      "metadata": {
        "id": "5PAqADAlZnyF"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decoder"
      ],
      "metadata": {
        "id": "eNcbK0YVmEDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(Layer):\n",
        "  def __init__(self, embeddings_dim, n_heads, latent_dim):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.embeddings_dim=embeddings_dim\n",
        "    self.n_heads=n_heads\n",
        "    self.latent_dim=latent_dim\n",
        "\n",
        "    self.attention_1=MultiHeadAttention(n_heads=n_heads, key_dim=embeddings_dim) # self-attention\n",
        "    self.attention_2=MultiHeadAttention(n_heads=n_heads, key_dim=embeddings_dim) #cross attention\n",
        "\n",
        "\n",
        "    self.dense_projection=tf.keras.Sequential(\n",
        "        [Dense(latent_dim, activation='relu'), Dense(embedding_dim)]\n",
        "    ) #feedforward layer\n",
        "\n",
        "    self.layernorm_1=LayerNormalization()\n",
        "    self.layernorm_2=LayerNormalization()\n",
        "    self.layernorm_3=LayerNormalization()\n",
        "\n",
        "  def call(self, inputs, encoder_output, encoder_mask, mask=None):\n",
        "    if mask is not None:\n",
        "      causal_mask = tf.linalg.band_part(\n",
        "          tf.ones([tf.shape(inputs)[0],\n",
        "                   tf.shape(inputs)[1],\n",
        "                   tf.shape(inputs)[1]], dtype=tf.int32), -1, 0)\n",
        "      # the role of causal mask is to prevent peeking into the future tokens for the decoder to predict better\n",
        "      # the band_part method makes it really easier to do this\n",
        "\n",
        "      mask = tf.cast(\n",
        "          mask[:, tf.newaxis, :], dtype='int32'\n",
        "      )\n",
        "      enc_mask = tf.cast(\n",
        "          enc_mask[:, tf.newaxis, :], dtype='int32'\n",
        "      )\n",
        "\n",
        "      T = tf.shape(mask)[2] # T is the number of queries from the decoder\n",
        "      padding_mask = tf.repeat(mask, T, axis=1)\n",
        "      cross_attn_mask = tf.repeat(enc_mask, T, axis=1)\n",
        "      combined_mask = tf.minimum(padding_mask, causal_mask)\n",
        "\n",
        "    attention_output_1=self.attention_1(query=inputs, key=inputs, value=inputs, attention_mask=combined_mask)\n",
        "    output_1=self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "    attention_output_2=self.attention_2(query=output_1, key=encoder_output, value=encoder_output, attention_mask=cross_attn_mask, return_attention_scores=True)\n",
        "    output_2=self.layernorm_2(output_1 + attention_output_2)\n",
        "\n",
        "    projection_output=self.dense_projection(output_2)\n",
        "\n",
        "    return self.layernorm_3(output_2 + projection_output)\n",
        "\n"
      ],
      "metadata": {
        "id": "cKJioxNfmGoq"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Full transformer Model"
      ],
      "metadata": {
        "id": "-ebLcx7XHYjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIMS=512\n",
        "LATENT_DIMS=2048\n",
        "NUM_HEADS=8\n",
        "NUM_LAYER=1\n",
        "NUM_EPOCH=10\n",
        "attention_scores={}"
      ],
      "metadata": {
        "id": "pN6sDoGWHbvj"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "encoder_inputs = Input(shape=(None,), dtype='int64', name='input_1')\n",
        "embeddings = Embeddings(ENGLISH_SEQUENCE_LENGTH, VOCAB_SIZE, EMBEDDING_DIMS)\n",
        "x, enc_mask = embeddings(encoder_inputs)\n",
        "\n",
        "\n",
        "for _ in range(NUM_LAYER): # there can be N number of layers as mentioned by paper\n",
        "  x = Encoder(EMBEDDING_DIMS, LATENT_DIMS, NUM_HEADS)(x)\n",
        "encoder_outputs = x\n",
        "\n",
        "decoder_inputs = Input(shape=(None,), dtype='int64', name='input_2')\n",
        "x = Embeddings(FRENCH_SEQUENCE_LENGTH, VOCAB_SIZE, EMBEDDING_DIMS)(decoder_inputs)\n",
        "\n",
        "for i in range(NUM_LAYER):\n",
        "  x, scores = Decoder(EMBEDDING_DIMS, LATENT_DIMS, NUM_HEADS)(x, encoder_outputs, enc_mask)\n",
        "  attention_scores[f'decoder_layer{i+1}_block2'] = scores\n",
        "\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "decoder_outputs = Dense(VOCAB_SIZE, activation='softmax')(x)\n",
        "\n",
        "attention_score_model = tf.keras.Model(\n",
        "    [encoder_inputs, decoder_inputs],\n",
        "    attention_scores, name='attention_score_model'\n",
        ")\n",
        "\n",
        "\n",
        "transformer = tf.keras.Model(\n",
        "    [encoder_inputs, decoder_inputs],\n",
        "    decoder_outputs, name='transformer'\n",
        ")\n",
        "\n",
        "transformer.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        },
        "id": "KeI40mXvIMMq",
        "outputId": "1582446e-ac42-45a9-807b-5fc70f8dadf3"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:1383: UserWarning: Layer 'encoder_6' looks like it has unbuilt state, but Keras is not able to trace the layer `call()` in order to build it automatically. Possible causes:\n",
            "1. The `call()` method of your layer may be crashing. Try to `__call__()` the layer eagerly on some test input first to see if it works. E.g. `x = np.random.random((3, 4)); y = layer(x)`\n",
            "2. If the `call()` method is correct, then you may need to implement the `def build(self, input_shape)` method on your layer. It should create all variables used by the layer (e.g. by calling `layer.build()` on all its children layers).\n",
            "Exception encountered: ''Exception encountered when calling CustomSelfAttention.call().\n",
            "\n",
            "\u001b[1mDimensions must be equal, but are 32 and 512 for '{{node multi_head_attention_5_1/custom_self_attention_5_1/sub_1}} = Sub[T=DT_FLOAT](multi_head_attention_5_1/custom_self_attention_5_1/truediv, multi_head_attention_5_1/custom_self_attention_5_1/mul)' with input shapes: [?,32,32], [?,32,512].\u001b[0m\n",
            "\n",
            "Arguments received by CustomSelfAttention.call():\n",
            "  • query=tf.Tensor(shape=(None, 32, 64), dtype=float32)\n",
            "  • key=tf.Tensor(shape=(None, 32, 64), dtype=float32)\n",
            "  • value=tf.Tensor(shape=(None, 32, 64), dtype=float32)\n",
            "  • masking=tf.Tensor(shape=(None, 32, 512), dtype=float32)''\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'encoder_6', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Exception encountered when calling Encoder.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'encoder_6' (of type Encoder). Either the `Encoder.call()` method is incorrect, or you need to implement the `Encoder.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\nException encountered when calling CustomSelfAttention.call().\n\n\u001b[1mDimensions must be equal, but are 32 and 512 for '{{node multi_head_attention_5_1/custom_self_attention_5_1/sub_1}} = Sub[T=DT_FLOAT](multi_head_attention_5_1/custom_self_attention_5_1/truediv, multi_head_attention_5_1/custom_self_attention_5_1/mul)' with input shapes: [?,32,32], [?,32,512].\u001b[0m\n\nArguments received by CustomSelfAttention.call():\n  • query=tf.Tensor(shape=(None, 32, 64), dtype=float32)\n  • key=tf.Tensor(shape=(None, 32, 64), dtype=float32)\n  • value=tf.Tensor(shape=(None, 32, 64), dtype=float32)\n  • masking=tf.Tensor(shape=(None, 32, 512), dtype=float32)\u001b[0m\n\nArguments received by Encoder.call():\n  • args=('<KerasTensor shape=(None, 32, 512), dtype=float32, sparse=False, name=keras_tensor_34>',)\n  • kwargs={'mask': 'None'}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-427b7ec36c15>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_LAYER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# there can be N number of layers as mentioned by paper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEMBEDDING_DIMS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLATENT_DIMS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_HEADS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mencoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-5e5bb6eeeb86>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# Apply the multi-head attention layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# Apply residual connection and layer normalization after attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-81041a855b92>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, query, key, value, attention_mask)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m# Pass mask as None if not provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mhead\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mheads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-c69961322c7f>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, query, key, value, masking)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmasking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmasking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0;36m1e10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mattention_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmasking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Encoder.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'encoder_6' (of type Encoder). Either the `Encoder.call()` method is incorrect, or you need to implement the `Encoder.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\nException encountered when calling CustomSelfAttention.call().\n\n\u001b[1mDimensions must be equal, but are 32 and 512 for '{{node multi_head_attention_5_1/custom_self_attention_5_1/sub_1}} = Sub[T=DT_FLOAT](multi_head_attention_5_1/custom_self_attention_5_1/truediv, multi_head_attention_5_1/custom_self_attention_5_1/mul)' with input shapes: [?,32,32], [?,32,512].\u001b[0m\n\nArguments received by CustomSelfAttention.call():\n  • query=tf.Tensor(shape=(None, 32, 64), dtype=float32)\n  • key=tf.Tensor(shape=(None, 32, 64), dtype=float32)\n  • value=tf.Tensor(shape=(None, 32, 64), dtype=float32)\n  • masking=tf.Tensor(shape=(None, 32, 512), dtype=float32)\u001b[0m\n\nArguments received by Encoder.call():\n  • args=('<KerasTensor shape=(None, 32, 512), dtype=float32, sparse=False, name=keras_tensor_34>',)\n  • kwargs={'mask': 'None'}"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMVtVyclKO/97ZUaQH8zUTm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}