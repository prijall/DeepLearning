{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnFZEmaqZvmY"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np, cv2, io, os, re, string, time, datetime\n",
        "import seaborn as sns, sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import (TextVectorization, Embedding)\n",
        "from keras.layers import MultiHeadAttention, LayerNormalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9Bkvwggaepq",
        "outputId": "e77caea9-79fa-4876-c6b1-8973a333f100"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-01-12 16:18:14--  https://www.manythings.org/anki/fra-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7943074 (7.6M) [application/zip]\n",
            "Saving to: ‘fra-eng.zip’\n",
            "\n",
            "fra-eng.zip         100%[===================>]   7.57M  6.34MB/s    in 1.2s    \n",
            "\n",
            "2025-01-12 16:18:16 (6.34 MB/s) - ‘fra-eng.zip’ saved [7943074/7943074]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#@ Downloading datasets:\n",
        "!wget https://www.manythings.org/anki/fra-eng.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzuI4hW6aq_q",
        "outputId": "7c27895b-0050-4496-8fe6-72819ea15271"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/fra-eng.zip\n",
            "  inflating: /content/dataset/_about.txt  \n",
            "  inflating: /content/dataset/fra.txt  \n"
          ]
        }
      ],
      "source": [
        "!unzip '/content/fra-eng.zip' -d '/content/dataset' # -d flag specifies directories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPc5HmT4bR4C"
      },
      "source": [
        "#### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GEjkt5-bT6B"
      },
      "outputs": [],
      "source": [
        "text_dataset=tf.data.TextLineDataset('/content/dataset/fra.txt') #each line is treated as separate string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y__LTpfEbuhy",
        "outputId": "87bc10f1-eb98-4844-d46b-b818414e06cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'Go.\\tVa !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)', shape=(), dtype=string)\n",
            "tf.Tensor(b'Go.\\tMarche.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8090732 (Micsmithel)', shape=(), dtype=string)\n",
            "tf.Tensor(b'Go.\\tEn route !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8267435 (felix63)', shape=(), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "for i in text_dataset.take(3):\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHGUPjuwb6Gx"
      },
      "outputs": [],
      "source": [
        "#@ Setting up the Parameters:\n",
        "VOCAB_SIZE=20000 #unique tokens from dataset, setting value 20000 for efficiency\n",
        "ENGLISH_SEQUENCE_LENGTH=32 #max length of i/p sequence[in tokens]\n",
        "FRENCH_SEQUENCE_LENGTH=32 #max len of o/p sequence[in tokens]\n",
        "EMBEDDINGS_DIM=512 #size of vectors to represent tokens(as per paper)\n",
        "BATCH_SIZE=128 #for data size processed during training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAuTBC_EeFMK"
      },
      "outputs": [],
      "source": [
        "#@ for english word:\n",
        "english_vectorize_layer=TextVectorization(\n",
        "                      standardize='lower_and_strip_punctuation',\n",
        "                      max_tokens=VOCAB_SIZE,\n",
        "                      output_mode='int', #mapping wrt to the integer index\n",
        "                      output_sequence_length=ENGLISH_SEQUENCE_LENGTH\n",
        ")\n",
        "\n",
        "#@ for french word:\n",
        "french_vectorize_layer=TextVectorization(\n",
        "                       standardize='lower_and_strip_punctuation',\n",
        "                       max_tokens=VOCAB_SIZE,\n",
        "                       output_mode='int',\n",
        "                       output_sequence_length=FRENCH_SEQUENCE_LENGTH\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlKHREVNhT2i"
      },
      "outputs": [],
      "source": [
        "def seperator(input_text):\n",
        "  split_text=tf.strings.split(input_text, '\\t')\n",
        "  return {\n",
        "      'input_1':split_text[0:1],\n",
        "      'input_2':'starttoken' + split_text[1:2]\n",
        "      }, split_text[1:2]+' endtoken'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndmYklVTi-IJ",
        "outputId": "5c6796fd-bb6f-4de0-fa94-807a01e554df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'hello'], dtype=object)>,\n",
              "  'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttokenprijal'], dtype=object)>},\n",
              " <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'prijal endtoken'], dtype=object)>)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text='hello\\tprijal'\n",
        "seperator(text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ustOzRdroLei"
      },
      "outputs": [],
      "source": [
        "#@ Initializing dataset:\n",
        "init_dataset=text_dataset.map(seperator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukk0KU5TpH3a",
        "outputId": "ebf6334b-4467-4d85-942d-d730701e4755"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttokenVa !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Va ! endtoken'], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttokenMarche.'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Marche. endtoken'], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttokenEn route !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'En route ! endtoken'], dtype=object)>)\n"
          ]
        }
      ],
      "source": [
        "for i in init_dataset.take(3):\n",
        "  print(i)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCOUUsunpsix"
      },
      "source": [
        "### Vocab Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zDyJI27QpvNp"
      },
      "outputs": [],
      "source": [
        "english_training_data=init_dataset.map(lambda x, y:x['input_1'])\n",
        "english_vectorize_layer.adapt(english_training_data)\n",
        "\n",
        "french_training_data=init_dataset.map(lambda x, y:y)\n",
        "french_vectorize_layer.adapt(french_training_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "V5DDzmf8L_fZ"
      },
      "outputs": [],
      "source": [
        "#@ Grouping and  Vectorization for training:\n",
        "def vectorizer(inputs, output):\n",
        "  return {'input_1':english_vectorize_layer(inputs['input_1']),\n",
        "          'input_2':french_vectorize_layer(inputs['input_2'])}, french_vectorize_layer(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qDlEbt5XM4r5",
        "outputId": "cd32678d-9f22-4efb-b930-51a633e4d191"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_MapDataset element_spec=({'input_1': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'input_2': TensorSpec(shape=(None,), dtype=tf.string, name=None)}, TensorSpec(shape=(None,), dtype=tf.string, name=None))>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "init_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HW8hWSGHNAbZ"
      },
      "outputs": [],
      "source": [
        "dataset=init_dataset.map(vectorizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "r5R0qqzbNYFZ",
        "outputId": "b8519c44-9f78-4fb0-e3b6-0697fe1dc730"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttokenVa !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Va ! endtoken'], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttokenMarche.'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Marche. endtoken'], dtype=object)>)\n",
            "({'input_1': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Go.'], dtype=object)>, 'input_2': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'starttokenEn route !'], dtype=object)>}, <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'En route ! endtoken'], dtype=object)>)\n"
          ]
        }
      ],
      "source": [
        "for i in init_dataset.take(3):\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-KNkkdXNfBx"
      },
      "outputs": [],
      "source": [
        "for i in dataset.take(1):\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQeOs1m8Nooa"
      },
      "outputs": [],
      "source": [
        "dataset=dataset.shuffle(2048).unbatch().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MPd8xmaN45p"
      },
      "outputs": [],
      "source": [
        "NUM_BATCHES=int(200000/BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3LvhBFsOCcy"
      },
      "outputs": [],
      "source": [
        "#@ Training and testing split\n",
        "train_dataset=dataset.take(int(0.9*NUM_BATCHES))\n",
        "val_dataset=dataset.skip(int(0.9*NUM_BATCHES))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXIaPrbnOWh5"
      },
      "source": [
        "### Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuLziKTkOZyh"
      },
      "outputs": [],
      "source": [
        "#@ Positional Encoding:\n",
        "def PositionalEncoding(d_model, SEQUENCE_LENGTH):\n",
        "  output=[]\n",
        "  for pos in range(SEQUENCE_LENGTH):\n",
        "    PE=np.zeros(d_model)\n",
        "    for i in range(d_model):\n",
        "      if i % 2 == 0: #even position, sine formula is used\n",
        "        PE[i]=np.sin(pos/(10000**(2*i/d_model)))\n",
        "      else:\n",
        "        PE[i]=np.cos(pos/(10000**(2*i/d_model)))\n",
        "    output.append(tf.expand_dims(PE, axis=0))\n",
        "  out=tf.concat(output, axis=0)\n",
        "  out=tf.expand_dims(out, axis=0)\n",
        "  return tf.cast(out, dtype=tf.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Am40vFY8Q0LS"
      },
      "outputs": [],
      "source": [
        "print(PositionalEncoding(512, 32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqa_KTf3T5Is"
      },
      "source": [
        "### Input Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xflRdAcHT89U"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Layer\n",
        "class Embeddings(Layer):\n",
        "  def __init__(self, sequence_length, vocab_size, embedding_dim):\n",
        "    super(Embeddings, self).__init__()\n",
        "    self.token_embeddings=Embedding(input_dim=vocab_size, output_dim=embedding_dim)\n",
        "    self.sequence_length=sequence_length\n",
        "    self.vocab_size=vocab_size\n",
        "    self.embedding_dim=embedding_dim\n",
        "\n",
        "  def call(self, inputs):\n",
        "    embedded_tokens=self.token_embeddings(inputs)\n",
        "    embedded_positions=PositionalEncoding(self.embedding_dim, self.sequence_length)\n",
        "    return embedded_tokens + embedded_positions\n",
        "\n",
        "  def compute_mask(self, inputs, mask=None):\n",
        "    return tf.math.not_equal(inputs, 0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noFlpky0YjJX"
      },
      "source": [
        "### Custome Attention Layer\n",
        "\n",
        "- Self attention layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DVoYgd-YrMN"
      },
      "outputs": [],
      "source": [
        "class CustomSelfAttention(Layer):\n",
        "  def __init__(self, model_size):\n",
        "    super(CustomSelfAttention, self).__init__()\n",
        "    self.model_size=model_size\n",
        "\n",
        "  def call(self, query, key, value, masking):\n",
        "    score=tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "    score/= tf.math.sqrt(tf.cast(self.model_size, dtype=tf.float32))\n",
        "\n",
        "    masking=tf.cast(masking, dtype=tf.float32)\n",
        "    score -= (1.0-masking)* 1e10\n",
        "\n",
        "    attention_weights=tf.nn.softmax(score, axis=1) * masking\n",
        "\n",
        "    head_output=tf.matmul(attention_weights, value)\n",
        "\n",
        "    return head_output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-headed Attention\n",
        "- Multihead Attention allows model to focus on different part of input sequence simultaneously and combine these prespective into comprehensive representation.\n",
        "\n",
        "- For example: \"Harry saw a man with binoculars'. This sentence can have two meanings, they are either it can be harry saw a man using binoculars or it can be harry saw a man who has binoculars. These both can be correct. So transformer has to understand both these meanings which self-attention fails to recognize that's why multi-head attention is used."
      ],
      "metadata": {
        "id": "f1Vqrwn1Sdsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(Layer):\n",
        "  def __init__(self, n_heads, key_dim):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "\n",
        "    self.n_heads=n_heads\n",
        "    self.dense_q=[Dense(key_dim//n_heads) for _ in range(n_heads)]\n",
        "    self.dense_k=[Dense(key_dim//n_heads) for _ in range(n_heads)]\n",
        "    self.dense_v=[Dense(key_dim//n_heads) for _ in range(n_heads)]\n",
        "    self.dense_o=Dense(key_dim)\n",
        "    self.attention=CustomSelfAttention(key_dim)\n",
        "\n",
        "  def call(self, query, key, value, attention_mask):\n",
        "    heads=[]\n",
        "\n",
        "    for i in range(n_heads):\n",
        "      print(f'head-{i}', self.dense_q[i](query).shape)\n",
        "      head=self.self_attention(self.dense_q[i](query), self.dense_k[i](key),\n",
        "                               self.dense_v[i](value), attention_mask)\n",
        "      heads.append(head)\n",
        "\n",
        "    heads=tf.concat(heads, axis=2)\n",
        "    heads=self.dense_o(heads)\n",
        "    return heads\n",
        "\n"
      ],
      "metadata": {
        "id": "XadG1w2LSioN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder"
      ],
      "metadata": {
        "id": "PfIpdo0cZhm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(Layer):\n",
        "  def __init__(self, embeddings_dim, dense_dim, n_heads):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.embeddings_dim=embeddings_dim\n",
        "    self.dense_dim=dense_dim\n",
        "    self.n_heads=n_heads\n",
        "    self.attention=MultiHeadAttention(n_heads=n_heads, key_dim=embeddings_dim)\n",
        "\n",
        "    self.dense_projection=tf.keras.Sequential([\n",
        "        Dense(self.dense_dims, activation='relu'),\n",
        "        Dense(self.embeddings_dims)\n",
        "    ])   #projection is done for enriching local relationship\n",
        "\n",
        "    self.layernorm1=LayerNormalization()\n",
        "    self.layernorm2=LayerNormalization()\n",
        "    self.supports_masking=True\n",
        "\n",
        "  def call(self, inputs, mask=None):\n",
        "    if mask in not None:\n",
        "      mask=tf.cast(mask[:, tf.newaxis, :], dtype='int32')\n",
        "      T=tf.shape(mask)[2]\n",
        "      padding_mask=tf.repeat(mask, T, axis=1)\n",
        "\n",
        "      attention_output=self.attention(query=inputs, value=inputs, key=inputs, attention_mask=padding_mask)\n",
        "\n",
        "      projection_input=self.layernorm_1(inputs + attention_output)\n",
        "      projection_output=self.dense_projection(projection_input)\n",
        "      return self.layernorm_2(projection_input + projection_output)"
      ],
      "metadata": {
        "id": "5PAqADAlZnyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decoder"
      ],
      "metadata": {
        "id": "eNcbK0YVmEDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(Layer):\n",
        "  def __init__(self, embeddings_dim, n_heads, latent_dim):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.embeddings_dim=embeddings_dim\n",
        "    self.n_heads=n_heads\n",
        "    self.latent_dim=latent_dim\n",
        "\n",
        "    self.attention_1=MultiHeadAttention(n_heads=n_heads, key_dim=embeddings_dim) # self-attention\n",
        "    self.attention_2=MultiHeadAttention(n_heads=n_heads, key_dim=embeddings_dim) #cross attention\n",
        "\n",
        "\n",
        "    self.dense_projection=tf.keras.Sequential(\n",
        "        [Dense(latent_dim, activation='relu'), Dense(embedding_dim)]\n",
        "    ) #feedforward layer\n",
        "\n",
        "    self.layernorm_1=LayerNormalization()\n",
        "    self.layernorm_2=LayerNormalization()\n",
        "    self.layernorm_3=LayerNormalization()\n",
        "\n",
        "  def call(self, inputs, encoder_output, encoder_mask, mask=None):\n",
        "\n",
        "     attention_output_1=self.attention_1(query=inputs, key=inputs, value=inputs)\n",
        "     output_1=self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "     attention_output_2=self.attention_2(query=output_1, key=encoder_output, value=encoder_output)\n",
        "     output_2=self.layernorm_2(output_1 + attention_output_2)\n",
        "\n",
        "     projection_output=self.dense_projection(output_2)\n",
        "\n",
        "     return self.layernorm_3(output_2 + projection_output)\n",
        "\n"
      ],
      "metadata": {
        "id": "cKJioxNfmGoq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOP82DK89fOg7KcvLYlH8fg"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}