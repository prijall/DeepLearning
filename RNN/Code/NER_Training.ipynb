{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAMpvOPt8SYB",
        "outputId": "a35f61ac-8f62-40e2-cfbb-96bc285764e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sklearn-crfsuite\n",
            "  Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting python-crfsuite>=0.9.7 (from sklearn-crfsuite)\n",
            "  Downloading python_crfsuite-0.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite) (1.5.2)\n",
            "Requirement already satisfied: tabulate>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite) (4.66.6)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->sklearn-crfsuite) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->sklearn-crfsuite) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->sklearn-crfsuite) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.0->sklearn-crfsuite) (3.5.0)\n",
            "Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading python_crfsuite-0.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.11 sklearn-crfsuite-0.5.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "#@ Importing Necessary dependencies and libraries:\n",
        "from nltk.tag import pos_tag\n",
        "!pip install sklearn-crfsuite\n",
        "from sklearn_crfsuite import CRF, metrics\n",
        "from sklearn.metrics import make_scorer, confusion_matrix\n",
        "from pprint import pprint\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from sklearn.pipeline import Pipeline\n",
        "import string\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger_eng')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YN-MZG479LLg"
      },
      "outputs": [],
      "source": [
        "#@ Data Loading:\n",
        "def load_data_conll(file_path):\n",
        "  myoutput, tokens, tags=[], [], []\n",
        "  with open(file_path, 'r') as fh:\n",
        "    for line in fh:\n",
        "      line=line.strip() #to remove leading and trailing  white space characters\n",
        "      if '\\t' not in line:\n",
        "        #sentences ended\n",
        "        myoutput.append([tokens, tags])\n",
        "        tokens, tags=[], []\n",
        "      else:\n",
        "        token ,tag=line.split('\\t')\n",
        "        tokens.append(token)\n",
        "        tags.append(tag)\n",
        "    fh.close()\n",
        "    return myoutput"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuoAGE14D8s3"
      },
      "source": [
        "### Getting features of all the tokens in sentence.\n",
        "\n",
        "##### Features:\n",
        "- **Token Context:** a window of 2 tokens on either side of current token, and current token.\n",
        "\n",
        "- **POS Context:**  a window of 2 tokens on either side of current tag, and current tag.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CeYXneB2E5wv"
      },
      "outputs": [],
      "source": [
        "def sentence2features(sentence):\n",
        "  features=[]\n",
        "  sentence_tags=pos_tag(sentence)\n",
        "  for i in range(0, len(sentence)):\n",
        "    token=sentence[i]\n",
        "    tokenfeatures={}\n",
        "\n",
        "    #@ token features:\n",
        "    #token\n",
        "    tokenfeatures['token']=token\n",
        "\n",
        "    #for 2 prev tokens\n",
        "    if i==0:\n",
        "      tokenfeatures['prevtoken']=tokenfeatures['prevsecondtoken']='<S>'\n",
        "    elif i==1:\n",
        "      tokenfeatures['prevtoken']=sentence[0]\n",
        "      tokenfeatures['prevsecondtoken']='</S>'\n",
        "    else:\n",
        "      tokenfeatures['prevtoken']=sentence[i-1]\n",
        "      tokenfeatures['prevsecondtoken']=sentence[i-2]\n",
        "\n",
        "    #for 2 next token\n",
        "    if i==len(sentence)-2:\n",
        "      tokenfeatures['nexttoken']=sentence[i+1]\n",
        "      tokenfeatures['nextsecondtoken']='</S>'\n",
        "\n",
        "    elif i==len(sentence)-1:\n",
        "      tokenfeatures['nexttoken']='</S>'\n",
        "      tokenfeatures['nextsecondtoken']='</S>'\n",
        "\n",
        "    else:\n",
        "      tokenfeatures['nexttoken']=sentence[i+1]\n",
        "      tokenfeatures['nextsecondtoken']=sentence[i+2]\n",
        "\n",
        "    #@ POS feature:\n",
        "\n",
        "    #current tag\n",
        "    tokenfeatures['tag']=sentence_tags[i][1]\n",
        "\n",
        "    #prev tag\n",
        "    if i==0:\n",
        "      tokenfeatures['prevtag']=tokenfeatures['prevsecondtag']='</S>'\n",
        "    elif i==1:\n",
        "      tokenfeatures['prevtag']=sentence_tags[0][1]\n",
        "      tokenfeatures['prevsecondtag']='</S>'\n",
        "    else:\n",
        "      tokenfeatures['prevtag']=sentence_tags[i-1][1]\n",
        "      tokenfeatures['prevsecondtag']=sentence_tags[i-2][1]\n",
        "\n",
        "    #next tag\n",
        "    if i==len(sentence)-2:\n",
        "      tokenfeatures['nexttag']=sentence_tags[i+1][1]\n",
        "      tokenfeatures['nextsecondtag']='</S>'\n",
        "\n",
        "    elif i==len(sentence)-1:\n",
        "      tokenfeatures['nexttag']='</S>'\n",
        "      tokenfeatures['nextsecondtag']='</S>'\n",
        "\n",
        "    else:\n",
        "      tokenfeatures['nexttag']=sentence_tags[i+1][1]\n",
        "      tokenfeatures['nextsecondtag']=sentence_tags[i+2][i]\n",
        "\n",
        "    features.append(tokenfeatures)\n",
        "  return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "J-fjLGn2K9ni"
      },
      "outputs": [],
      "source": [
        "#@ Extracting features:\n",
        "def get_features_conll(conll_data):\n",
        "  features=[]\n",
        "  labels=[]\n",
        "  for sentence in conll_data:\n",
        "    features.append(sentence2features(sentence[0]))\n",
        "    labels.append(sentence[1])\n",
        "  return features, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCyrcpL49q7b"
      },
      "source": [
        "### Training Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "r1HDQRk49tHL"
      },
      "outputs": [],
      "source": [
        "def train_seq(X_train, Y_train, X_val, Y_val):\n",
        "  crf=CRF(algorithm='lbfgs', c1=0.1, c2=10, max_iterations=50)\n",
        "  crf.fit(X_train, Y_train)\n",
        "  labels=list(crf.classes_)\n",
        "\n",
        "  # Check if labels is empty and handle accordingly\n",
        "  if not labels:\n",
        "    print(\"Warning: No labels found in the trained model. Check training data and model parameters.\")\n",
        "    return  # or raise an exception\n",
        "\n",
        "  #testing:\n",
        "  y_pred=crf.predict(X_val)\n",
        "  sorted_labels=sorted(labels, key=lambda name: (name[1:], name[0]))\n",
        "  print(metrics.flat_f1_score(Y_val, y_pred,average='weighted', labels=labels))\n",
        "  print(metrics.flat_classification_report(Y_val, y_pred, labels=sorted_labels, digits=3))\n",
        "  get_confusion_matrix(Y_val, y_pred, labels=sorted_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_X24MYBdIBAd"
      },
      "source": [
        "### Confusion matrix helper fucntion:\n",
        "- Note: copied below two functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "vuewzmsZIGuV"
      },
      "outputs": [],
      "source": [
        "def print_cm(cm, labels):\n",
        "    print(\"\\n\")\n",
        "    \"\"\"pretty print for confusion matrixes\"\"\"\n",
        "    columnwidth = max([len(x) for x in labels] + [5])  # 5 is value length\n",
        "    empty_cell = \" \" * columnwidth\n",
        "    # Print header\n",
        "    print(\"    \" + empty_cell, end=\" \")\n",
        "    for label in labels:\n",
        "        print(\"%{0}s\".format(columnwidth) % label, end=\" \")\n",
        "    print()\n",
        "    # Print rows\n",
        "    for i, label1 in enumerate(labels):\n",
        "        print(\"    %{0}s\".format(columnwidth) % label1, end=\" \")\n",
        "        sum = 0\n",
        "        for j in range(len(labels)):\n",
        "            cell = \"%{0}.0f\".format(columnwidth) % cm[i, j]\n",
        "            sum =  sum + int(cell)\n",
        "            print(cell, end=\" \")\n",
        "        print(sum) #Prints the total number of instances per cat at the end."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "dPan1IU3IMcE"
      },
      "outputs": [],
      "source": [
        "#python-crfsuite does not have a confusion matrix function,\n",
        "#so writing it using sklearn's confusion matrix and print_cm from github\n",
        "def get_confusion_matrix(y_true,y_pred,labels):\n",
        "    trues,preds = [], []\n",
        "    for yseq_true, yseq_pred in zip(y_true, y_pred):\n",
        "        trues.extend(yseq_true)\n",
        "        preds.extend(yseq_pred)\n",
        "    print_cm(confusion_matrix(trues,preds,labels),labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "SyrMPZAaIgEE",
        "outputId": "dacf70ea-80be-4850-c6fd-167511374347"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8cbb224c-b694-4477-b56c-65c559578a59\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8cbb224c-b694-4477-b56c-65c559578a59\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving test.txt to test (4).txt\n",
            "Saving train.txt to train (5).txt\n",
            "Training a sequence classification model with CRF:\n",
            "Warning: No labels found in the trained model. Check training data and model parameters.\n",
            "Done with sequence model\n"
          ]
        }
      ],
      "source": [
        "#@ Calling all our functions inside main method:\n",
        "\n",
        "def main():\n",
        "  try:\n",
        "    from google.colab import files\n",
        "    uploaded=files.upload()\n",
        "\n",
        "    #files in Data/conlldata\n",
        "    train_path='train.txt'\n",
        "    test_path='test.txt'\n",
        "  except:\n",
        "    train_path='Data/conlldata/train.txt'\n",
        "    test_path='Data/conlldata/test.txt'\n",
        "\n",
        "  conll_train=load_data_conll(train_path)\n",
        "  conll_val=load_data_conll(test_path)\n",
        "\n",
        "  print('Training a sequence classification model with CRF:')\n",
        "  features, labels=get_features_conll(conll_train)\n",
        "  valfeatures, vallabels=get_features_conll(conll_val)\n",
        "  train_seq(features, labels, valfeatures, vallabels)\n",
        "  print('Done with sequence model')\n",
        "\n",
        "if __name__=='__main__':\n",
        "  main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjpz+X8O2cwWhVKhu8PXzx"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}